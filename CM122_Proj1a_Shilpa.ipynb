{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import argparse\n",
        "import numpy as np\n",
        "import time\n",
        "import zipfile\n",
        "import math\n",
        "import textwrap\n",
        "import pprint as pprint\n",
        "\n",
        "from collections import defaultdict, Counter, OrderedDict\n",
        "\n",
        "ref_raw = '/content/sample_1000_reference_genome.fasta'\n",
        "reads_raw = '/content/sample_1000_with_error_paired_reads.fasta'\n",
        "\n",
        "refs_file = '/content/sample_1000_reference_genome.fasta'\n",
        "reads_file = '/content/sample_1000_with_error_paired_reads.fasta'\n",
        "\n",
        "def reads_format(reads_file):\n",
        "    try:\n",
        "        with open(reads_file, 'r') as read:\n",
        "            first_line = True\n",
        "            count = 0\n",
        "            reads = []\n",
        "            for line in read:\n",
        "                count += 1\n",
        "                if first_line:\n",
        "                    first_line = False\n",
        "                    continue\n",
        "                ends = line.strip().split(',')\n",
        "                reads.append(ends)\n",
        "        return reads\n",
        "    except IOError:\n",
        "        print(\"error reading \", reads_file)\n",
        "        return None\n",
        "\n",
        "def ref_format(ref_fn):\n",
        "    try:\n",
        "        with open(ref_fn, 'r') as genome:\n",
        "            first_line = True\n",
        "            ref_genome = ''\n",
        "            for line in genome:\n",
        "                if first_line:\n",
        "                    first_line = False\n",
        "                    continue\n",
        "                ref_genome += line.strip()\n",
        "        return ref_genome\n",
        "    except IOError:\n",
        "        print(\"error reading \", ref_fn)\n",
        "        return None\n",
        "\n",
        "# ref = formatted file\n",
        "def refDict(ref, k):\n",
        "    d = {}\n",
        "    for i in range(len(ref)-k):\n",
        "        seq = ref[i:i+k]\n",
        "        d.setdefault(seq, []).append(i)\n",
        "    return d\n",
        "# ^ create genome data structure dict for k-mer"
      ],
      "metadata": {
        "id": "TOHRx8LcNdjI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_mer_maps = {}\n",
        "nucleotides = ['A', 'C', 'G', 'T']\n",
        "for i in range(53):\n",
        "    k_mer_maps[i] = refDict(ref_format(refs_file), i)"
      ],
      "metadata": {
        "id": "jbnTOcVCNkw1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "b8bc3f9e-8768-4721-fd8d-6ff534f82b82"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error reading  /content/sample_1000_reference_genome.fasta\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-73e0cc9b1718>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnucleotides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'G'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'T'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m53\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mk_mer_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrefDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefs_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-a0de58f84f05>\u001b[0m in \u001b[0;36mrefDict\u001b[0;34m(ref, k)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrefDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def align(read, n = 3): #breaks up the reads into n sections\n",
        "  readsArray = []\n",
        "  length = len(read)\n",
        "  if n == 3:\n",
        "    return read[:length // n], read[length // 3:2 * length // 3], read[2 * length // 3:length]\n",
        "  else:\n",
        "    for i in range(1, n): #goes up to n - 1\n",
        "    # this is for length % n == n-1\n",
        "      if length % 3 == i:\n",
        "       return read[:length // n + (i - 1)], read[length // n+i-1 : 2*length // n + i], read[2*length // n + i:length]\n",
        "\n",
        "# NEED TO WRITE GENERAL CODE:\n",
        "# split string of arbitrary length into arbitrary # of sections\n",
        "# return array of reads (right now it returns the strings themselves, so\n",
        "# if we return an array I'll need to edit the code in substitutions() that depends on the 3 parts of the read)"
      ],
      "metadata": {
        "id": "PFuGM_rlCgbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hamming_distance(p, q):\n",
        "  return sum([(1 if p[i] != q[i] else 0) for i in range(len(p))])\n",
        "  \n",
        "def neighbors(read, d = 2):\n",
        "  if d == 0:\n",
        "    return {read}\n",
        "  if len(read) == 1:\n",
        "    return {'A', 'C', 'G', 'T'}\n",
        "  neighborhood = set()\n",
        "  suffix_neighbors = neighbors(read[1:], d)\n",
        "  for text in suffix_neighbors:\n",
        "    if hamming_distance(read[1:], text) < d:\n",
        "      for i in ['A', 'C', 'G', 'T']:\n",
        "        neighborhood.add(i + text)\n",
        "    else:\n",
        "      neighborhood.add(read[0] + text)\n",
        "  return neighborhood\n",
        "\n",
        "neighbors('TATCTACACATTACGAG')\n",
        "\n",
        "for i in range(len(read_f)):\n",
        "  read = reads_notitle[i][0]\n",
        "  readNeighbor = neighbors(read, 1) #compute the 1-neighborhood of a read\n"
      ],
      "metadata": {
        "id": "ikAiS7YsLGSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find keys of substitutions for a given read\n",
        "def substitutions(reads_file, reference_genome_file, threshold = 4):\n",
        "\n",
        "  reads = reads_format(reads_file)\n",
        "  reference_genome = ref_format(reference_genome_file)\n",
        "  differences = {}\n",
        "  alignment_table = [k_mer_maps]\n",
        "\n",
        "  # tried to make alignment_table into a dict for faster access\n",
        "  # failed\n",
        "  # alignment_dict = {}\n",
        "  # for key in k_mer_maps.keys():\n",
        "  #   alignment_dict[key] = (dict(zip(frozenset(k_mer_maps[key]))))\n",
        "  \n",
        "  genome_length = len(reference_genome)\n",
        "\n",
        "  whichread = 0\n",
        "\n",
        "  numSplits = 4 #testing splitting into arbitrary n sections\n",
        "  read_sections2 = align(reads[0::2], numSplits) # should only be passing in contents, not titles. not sure how below code takes care of that. \n",
        "  print(len(read_sections2))\n",
        "  # print(\"read_sections2[0] at 4 splits: \", read_sections2[0])\n",
        "  # print(\"read_sections2[1] at 4 splits: \", read_sections2[1])\n",
        "  # print(\"read_sections2[2] at 4 splits: \", read_sections2[2]) #should be third\n",
        "\n",
        "  #iterate thru all reads\n",
        "  for read_pair in reads: # READ PAIR? !!!!!!\n",
        "    for read in read_pair:\n",
        "      length = len(read)\n",
        "      if read in k_mer_maps[length].keys(): #look up FULL read in genome data struct to see if it's perfect\n",
        "        alignment_table.append('-' * k_mer_maps[length][read][0] + read + '-' * (genome_length - (k_mer_maps[length][read][0] + length)))\n",
        "        continue\n",
        "\n",
        "      # split up read into n sections\n",
        "      read_sections = align(read) \n",
        "      # temp = []\n",
        "      # for i in range(numSplits):\n",
        "      #   temp.append(len(read_sections[i]))\n",
        "      # read_section_lengths = tuple(temp)\n",
        "      # print(read_section_lengths)\n",
        "      read_section_lengths = (len(read_sections[0]), len(read_sections[1]), len(read_sections[2]))\n",
        "\n",
        "      valid_sections = [[], [], []] # make array of valid sections\n",
        "      for i in range(3): #numsplits = 3\n",
        "        for neighbor_read in neighbors(read_sections[i], 2):\n",
        "          if neighbor_read in k_mer_maps[read_section_lengths[i]].keys():\n",
        "            for position in k_mer_maps[read_section_lengths[i]][neighbor_read]:\n",
        "              valid_sections[i].append((neighbor_read, position))\n",
        "              # if a substring of read is valid append it\n",
        "      \n",
        "      # if indices of each valid section create full length read\n",
        "      # then add to array of complete sequence finds\n",
        "      complete_sequence_finds = []\n",
        "      for find_a in valid_sections[0]:\n",
        "        for find_b in valid_sections[1]:\n",
        "          if find_a[1] + read_section_lengths[0] == find_b[1]:\n",
        "            for find_c in valid_sections[2]:\n",
        "              if find_b[1] + read_section_lengths[1] == find_c[1]:\n",
        "                complete_sequence_finds.append((find_a[0] + find_b[0] + find_c[0], find_a[1]))\n",
        "      \n",
        "      # for each entry in complete sequence finds, ask if it's a substitution\n",
        "      for find in complete_sequence_finds:\n",
        "        referece_genome_portion = find[0] #string\n",
        "        portion_location = find[1] #position\n",
        "        \n",
        "        alignment_table.append('-' * portion_location + read + '-' * (genome_length - (portion_location + length)))\n",
        "        substitutions = [(portion_location + i, referece_genome_portion[i], read[i]) for i in range(length) if read[i] != referece_genome_portion[i]]\n",
        "        for sub in substitutions:\n",
        "          differences[sub] = differences.get(sub, 0) + 1 #append to differences dict. if it already exists, iterate, if not, initialize with 0 (i think)\n",
        "\n",
        "  return sorted([(key, differences[key]) for key in differences.keys() if differences[key] > threshold])\n",
        "  # if differences[key] above threshold we're convinced it's not an error"
      ],
      "metadata": {
        "id": "Kj3FCjrvQhB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = substitutions(reads_raw, ref_raw)\n",
        "\n",
        "def pprint_1a(output):\n",
        "  for (ind, orig, new), val in output:\n",
        "    print(\">S\" + str(ind), orig, new)\n",
        "\n",
        "pprint_1a(output)"
      ],
      "metadata": {
        "id": "Xnt5L3bTP2hy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}